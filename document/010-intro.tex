\chapter{Introduction}
\label{sec:introduction}

\section{Context}

% 1.1 Background and Context
% =============================================================================
% Begin by providing an overview of the field of neural networks and their
% importance in various domains such as machine learning, computer vision,
% natural language processing, and more. Briefly mention the rapid advancements
% in neural network architectures and techniques that have led to significant
% breakthroughs.

\Textcite{frenayParameterinsensitiveKernelExtreme2011} presented a
parameter-insensitive kernel inspired from extreme learning machines (ELMs
\cite{huangExtremeLearningMachine2006}). According to the authors, the
meta-parameter associated with the kernel does not affect the performance of the
results obtained. In the paper they demonstrate the effectiveness of the kernel
in a Support Vector Regression (SVR) task. The results obtained with this kernel
are not significantly different from the results obtained in the
\emph{state-of-the-art} of each dataset using Gaussian kernels.

If the kernel is indeed parameter-insensitive, then it is possible that other
infinite neural network kernels also have this property. The aim of this project
is to study the effects of these infinite neural network kernels in extreme
learning machines; understanding their behaviour in practical learning problems,
with a special focus on the dependence (or lack of) of performance on the kernel
hyperparameters.

Having a parameter-insensitive kernel has the potential to cut down on the time
spent on hyperparameter tuning, which is one of the most time-consuming tasks in
machine learning.

\subsection{Scope and Limitations}%
\label{sub:scope_and_limitations}

Due to the time and computational constraints, the scope of this project is
limited to the study on a few datasets. The datasets chosen try to cover a wide
range of characteristics, but are in no way exhaustive. But should be enough to
provide a good understanding of the behaviour of the kernels and gain some
insights on their limitations.


% 1.2 Problem Statement
% ==============================================================================
% Introduce the specific problem you're addressing in your thesis â€“ the effects
% of infinite neural network kernels. Explain why this topic is relevant and how
% it fits within the broader landscape of neural network research. Highlight any
% existing challenges, limitations, or gaps in the current understanding of this
% concept.

% 1.3 Objectives and Research Questions
% ==============================================================================
% Clearly state the objectives of your thesis. What do you aim to achieve
% through your research? Identify the central research questions that will guide
% your investigation into the effects of infinite neural network kernels.


% 1.4 Significance of the Study
% ==============================================================================
% Discuss the potential implications and applications of understanding infinite
% neural network kernels. How might this knowledge contribute to improving
% neural network design, performance, or interpretability? Highlight the
% importance of addressing this topic to advance the field of neural networks.

% 1.5 Scope and Limitations
% ==============================================================================
% Define the scope of your research. Specify the boundaries of your
% investigation, such as the specific types of neural networks, data, and
% mathematical principles you will focus on. Also, acknowledge any limitations
% that might affect the generalizability of your findings.

% 2.2 Kernel Methods in Machine Learning
% ==============================================================================
% Introduce the concept of kernel methods in machine learning, emphasizing their
% use in support vector machines (SVMs) and other algorithms. Explain how
% kernels allow algorithms to operate in a higher-dimensional feature space
% without explicitly calculating the coordinates.

% \subsection{Infinite Neural Network Kernels}%
% 2.3 Infinite Kernels and Their Implications
% ==============================================================================
% Define what is meant by "infinite neural network kernels." Explore how
% infinite kernels can potentially offer novel insights into neural network
% behavior, representation learning, and generalization. Touch upon any related
% mathematical concepts that will be relevant to your analysis.

% \section{Related Work}%
% \label{sec:related_work}

% 3. Related Work
% ==============================================================================

% 3.1 Studies on Neural Network Kernels
% ==============================================================================
% Discuss existing research or studies that have explored neural network
% kernels, both finite and infinite. Highlight any findings, methodologies, or
% gaps in the literature that your thesis aims to address.

% 3.2 Applications and Impact
% ==============================================================================
% Provide examples of how understanding neural network kernels, particularly
% infinite ones, has impacted real-world applications or theoretical
% advancements in machine learning and related fields.

% 6. Conclusion
% ==============================================================================
% Summarize the key points you've discussed in the introduction and provide a
% smooth transition to the subsequent chapters. Emphasize the importance of your
% research in advancing the understanding of infinite neural network kernels and
% its potential implications.

% Remember, the introduction should capture the reader's attention, provide
% context, and set the stage for the rest of your thesis. Make sure your writing
% is clear, concise, and well-organized, and consider revisiting and refining
% the introduction after you've completed the other sections of your thesis to
% ensure it accurately reflects your research's scope and findings.

\section{Methodology}

\subsection{Data Collection and Generation}%

Due to the nature of the analysis, we need a wide variety of datasets in order
to observe the behaviour of the kernels in different scenarios. The chosen
datasets are summarized in \cref{tab:datasets_regression,tab:datasets_classification}.

\begin{table}[H]
    \begin{threeparttable}
        \caption{Regression datasets used in this thesis}
        \label{tab:datasets_regression}
        \input{tables/datasets.tex}
        \begin{tablenotes}
            \item[a] The Bank and Pumadyn consist of 8 synthetic datasets each. With different
            number of features (8/32), more linearity or less linearity and more or less noise.
        \end{tablenotes}
        % INFO: keep this up to date with scripts/tables.jl
    \end{threeparttable}
\end{table}

\begin{table}[H]
    \caption{Classification datasets used in this thesis}
    \label{tab:datasets_classification}
    \input{tables/datasets_cat.tex}
    % INFO: keep this up to date with scripts/tables.jl
\end{table}

\subsection{Experiments and Goals}%

We can classify the experiments in two groups according to their purposes. The
first group of experiments is used to understand the performance of the
different kernels and their hyperparameters relative to each other. This is
similar to the experiments performed by
\textcite{frenayParameterinsensitiveKernelExtreme2011}, but with a wider range
of datasets and using additional kernels.

The second batch of experiments takes the results from the first group and
applies meta-learning techniques with the goal of determining if it is possible
to reach data driven conclusions about which kernel and hyperparameters to use
for a given dataset.

In \cref{sec:experiments} we describe the experimental design in more detail.

% TODO: Gender competency
% https://www.fib.upc.edu/en/studies/masters/master-data-science/masters-thesis/gender-competency
%
% Wong colorscheme (used in Makie) \cite{wongPointsViewColor2011}
% + patterns when possible

\subsection{Diversity and Inclusion}%

The datasets used in this thesis are publicly available and have been widely
used in other studies. Some datasets concern sensitive topics such as cancer,
alcohol consumption or community crime rates. However, the aim of the thesis is
not to study the data itself, but the behaviour of the kernels in different
scenarios. As such, the datasets were chosen based on their characteristics and
not on the topic they represent and
aiming to have a diverse set of datasets.

Nevertheless, we acknowledge that there may be a bias in the selection of the
datasets. Since we had limited computational resources and time to perform the
experiments, the number of datasets is limited and not as diverse as we would
like.

A special effort has been taken to ensure that the data visualizations
presented in this thesis are accessible. The colors are selected to be
distinguishable by people with color blindness and the figures are designed to
be readable when printed in black and white. In particular,
we used the colors described by \textcite{wongPointsViewColor2011} and
the perceptually uniform colors from \textcite{crameriScientificColourMaps2023}.
When applicable, we used patterns and changes in line styles or markers to
further distinguish the different series in the plots.

% \subsection{Experimental Design}%

\section{Structure of the thesis}
% TODO: make sure this is up to date.

\Cref{sec:theoretical_background} gives an overview of the theoretical
background of the kernels used in this thesis, showing their derivation and
properties. In \cref{sec:implementation} we describe the implementation of the
kernels in \emph{C} and the wrappers used to interface with them from
\emph{Julia}. \Cref{sec:experiments} discussed the experimental design.
\Cref{sec:analysis} provides an analysis of the results from the experiments
and discusses the implications of the findings.
\Cref{sec:conclusions} concludes the thesis and provides some ideas for future
work.

% 4. Methodology
% ==============================================================================

% 4.1 Data Collection and Preparation
% ==============================================================================
% Explain how you plan to gather or generate the data necessary for your
% analysis. If applicable, clarify the characteristics of the datasets you will
% use and how they relate to neural network kernels.

% 4.2 Experimental Design
% ==============================================================================
% Outline the experimental procedures you will follow to investigate the effects
% of infinite neural network kernels. Detail the neural network architectures,
% training strategies, and evaluation metrics you intend to use.

% 5. Structure of the Thesis
% ==============================================================================

% Provide a brief overview of how your thesis is organized, highlighting the
% main sections and the flow of your argument.


\section{Contributions}

% TODO
The main contributions of this thesis are:
\begin{enumerate}
    \item Updated libsvm in nixpkgs repository and enabled OpenMP support\footnote{\url{https://github.com/NixOS/nixpkgs/pull/221325}}
    \item Extended libsvm to support additional kernels\footnote{\url{https://github.com/leixb/libsvm}}
    \item Extended the Julia wrapper for libsvm to support these additional kernels and added additional
          features to report and limit the iterations of the solver\footnote{\url{https://github.com/leixb/LIBSVM.jl}}
\end{enumerate}
